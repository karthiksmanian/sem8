{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a00c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IR PS3\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "809fa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_time_all = open(\"/home/karthikmsd/sem8/20XW86-IR-LAB/ws3/dataset-info/TIME.ALL\", 'r')\n",
    "f_query = open(\"/home/karthikmsd/sem8/20XW86-IR-LAB/ws3/dataset-info/TIME.QUE\", 'r')\n",
    "f_stp = open(\"/home/karthikmsd/sem8/20XW86-IR-LAB/ws3/dataset-info/TIME.STP\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dea39025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_documents(f):\n",
    "    documents = []\n",
    "    fstr = f.read()\n",
    "    regex = r\"\\*TEXT\\s+\\d{3}\\s+\\d{2}/\\d{2}/\\d{2}\\s+PAGE\\s+\\d{3}\\n\\n\"\n",
    "    \n",
    "    iters = []\n",
    "    result = re.finditer(regex, fstr, re.DOTALL)\n",
    "    for key in result:\n",
    "        iters.append(key)\n",
    "\n",
    "    for i in range(len(iters)-1):\n",
    "        i1 = iters[i].span()[1]\n",
    "        i2 = iters[i+1].span()[0]\n",
    "        \n",
    "        documents.append(fstr[i1:i2])\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af824db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_queries(f):\n",
    "    text = f.read()\n",
    "    pattern = r'\\*FIND\\s+\\d+\\s+(.*?)(?=\\s*\\*FIND\\s+\\d+|$)'\n",
    "    result = []\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    for match in matches:\n",
    "        result.append(match.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "880eb971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stopwords(f):\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "    \n",
    "    return set(nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "beec9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = parse_documents(f_time_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fda1418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6e0e4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = parse_queries(f_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9c00a49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samp_doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "62e314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = parse_stopwords(f_stp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41049f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# 1. conv. to lowercase\n",
    "# 2. tokenization\n",
    "# 3. stopword, spl char removal\n",
    "# 4. stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4137998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2d163c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "689bf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "54cecf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alli nassau decemb 1960 propos help nato develop nuclear strike forc europ attempt devis plan studi nassau accord presid kennedi prime minist macmillan european saw emerg outlin nuclear nato want support sprang crisi cancel skybolt missil offer suppli'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(samp_doc)[:251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "058b20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "    processed_docs.append(transform_text(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eaffc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "61484892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wik = (TFik/LENi)*log(N+1)/0.5+DFk\n",
    "# TFik - term frequency within doc.\n",
    "# LENi - len of current doc.\n",
    "# N - total docs\n",
    "# DFk - document frequency of the word (no. of documents for which the word exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e872cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "15275a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, mymap):\n",
    "    return mymap[word]\n",
    "\n",
    "def DF(word, corpus_maps):\n",
    "    count = 0\n",
    "    \n",
    "    for hm in corpus_maps:\n",
    "        if word in hm:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def calculate_weights(doc, doc_map, corpus_maps):\n",
    "    vector = [0]*len(doc_map)\n",
    "    \n",
    "    mymap = {}\n",
    "    \n",
    "    for i in doc.split():\n",
    "        if i in mymap:\n",
    "            mymap[i] +=1\n",
    "        else:\n",
    "            mymap[i] = 1\n",
    "    \n",
    "    for word in doc.split():\n",
    "        TFik = TF(word, mymap)\n",
    "        LENi = len(doc)\n",
    "        N = len(corpus_maps)\n",
    "        DFk = DF(word, corpus_maps)\n",
    "        \n",
    "        try:\n",
    "            index = list(doc_map.keys()).index(word)\n",
    "            vector[index] = (TFik/LENi)*(math.log(N+1)/(0.5+DFk))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a68f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = {}\n",
    "\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word in doc_map:\n",
    "            doc_map[word] += 1\n",
    "        else:\n",
    "            doc_map[word] = 1\n",
    "\n",
    "doc_matrix = []\n",
    "\n",
    "list_of_maps = []\n",
    "\n",
    "for doc in processed_docs:\n",
    "    hm = {}\n",
    "    \n",
    "    for word in doc.split():\n",
    "        if word in hm:\n",
    "            hm[word] += 1\n",
    "        else:\n",
    "            hm[word] = 1\n",
    "    \n",
    "    list_of_maps.append(hm)\n",
    "\n",
    "for doc in processed_docs:\n",
    "    vector = calculate_weights(doc, doc_map, list_of_maps)\n",
    "    doc_matrix.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb920f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ddcd6929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 13817)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(doc_matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0d05d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting queries to TD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "26003a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\\n\\nSUPPRESSING THE BUDDHISTS .',\n",
       " \"EFFORTS OF AMBASSADOR HENRY CABOT LODGE TO GET VIET NAM'S\\n\\nPRESIDENT DIEM TO CHANGE HIS POLICIES OF POLITICAL REPRESSION .\",\n",
       " 'NUMBER OF TROOPS THE UNITED STATES HAS STATIONED IN SOUTH\\n\\nVIET NAM AS COMPARED WITH THE NUMBER OF TROOPS IT HAS STATIONED\\n\\nIN WEST GERMANY .',\n",
       " 'U.S . POLICY TOWARD THE NEW REGIME IN SOUTH VIET NAM WHICH OVERTHREW\\n\\nPRESIDENT DIEM .',\n",
       " 'PERSONS INVOLVED IN THE VIET NAM COUP .']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c40bdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_queries = []\n",
    "\n",
    "for query in queries:\n",
    "    processed_queries.append(transform_text(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1040c41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kennedi administr pressur ngo dinh diem stop suppress buddhist',\n",
       " 'effort ambassador henri cabot lodg viet presid diem chang polici polit repress',\n",
       " 'number troop unit state station south viet nam compar number troop station west germani',\n",
       " 'polici new regim south viet nam overthrew presid diem',\n",
       " 'person involv viet nam coup']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bebb498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5521f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_docs(query):\n",
    "    processed_query = transform_text(query)\n",
    "    query_td = calculate_weights(processed_query, doc_map, list_of_maps)\n",
    "    \n",
    "    ret = []\n",
    "    for i in range(len(doc_matrix)):\n",
    "        vec1 = np.array(doc_matrix[i])\n",
    "        vec2 = np.array(query_td)\n",
    "        \n",
    "        ret.append((i, cosine_similarity([vec1], [vec2])[0][0]))\n",
    "    \n",
    "    ret.sort(key= lambda x:-x[1])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d073bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \n",
      "KENNEDY ADMINISTRATION PRESSURE ON NGO DINH DIEM TO STOP\n",
      "\n",
      "SUPPRESSING THE BUDDHISTS .\n"
     ]
    }
   ],
   "source": [
    "search_res = fetch_docs(queries[0])[:12]\n",
    "print(f\"Query: \\n{queries[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "92f2bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document: 1, Calculated cosine similarity: 0.18742347658203506\n",
      "\n",
      "south viet nam the buddhist crisis in saigon's huge xa\n",
      "\n",
      "loi pagoda, buddhist monks and nuns were holding a 48-hour hunger\n",
      "\n",
      "strike against the regime of south viet nam's president ngo dinh diem .\n",
      "\n",
      "expecting trouble, police sealed off nearby streets wit\n",
      "\n",
      "Retrieved Document: 2, Calculated cosine similarity: 0.15482544638791104\n",
      "\n",
      "south viet nam 2-12 the religious crisis a dusk-to-dawn curfew emptied\n",
      "\n",
      "the streets of the ancient vietnamese capital of hue, 400 miles north\n",
      "\n",
      "of saigon . riot police and armored personnel carriers patrolled the\n",
      "\n",
      "dark and deserted city . roadblocks we\n",
      "\n",
      "Retrieved Document: 3, Calculated cosine similarity: 0.12006237606411654\n",
      "\n",
      "south viet nam : the new regime for a while, saigon looked\n",
      "\n",
      "like a city liberated . vietnamese g.i.s guarding public buildings\n",
      "\n",
      "munched oranges, bananas and candy, showered on them by civilians\n",
      "\n",
      "grateful for the overthrow of the regime . pretty girls\n",
      "\n",
      "Retrieved Document: 4, Calculated cosine similarity: 0.11748569263036349\n",
      "\n",
      "south viet nam the crackdown over and\n",
      "\n",
      "over, the desperate voice shouted into the telephone : \" they are\n",
      "\n",
      "breaking into xa loi pagoda . they are breaking into xa loi pagoda . \"\n",
      "\n",
      "in the background, gunfire mingled with the confused screams of\n",
      "\n",
      "buddhist\n",
      "\n",
      "Retrieved Document: 5, Calculated cosine similarity: 0.11075925437569079\n",
      "\n",
      "south viet nam suicide series it was the most macabre week in\n",
      "\n",
      "south viet nam's three-month-old religious and political crisis . in\n",
      "\n",
      "saigon, an 18-year-old girl tried unsuccessfully to cut off her left\n",
      "\n",
      "hand \" as a humble offering to buddha while our\n",
      "\n",
      "Retrieved Document: 6, Calculated cosine similarity: 0.0921780977292326\n",
      "\n",
      "south viet nam trial by fire the automobile at the head of the\n",
      "\n",
      "procession of saffron-robed buddhist monks in saigon suddenly choked to\n",
      "\n",
      "a stop at an intersection . the occupants of the car lifted its hood as\n",
      "\n",
      "chanting priests began forming a circle s\n",
      "\n",
      "Retrieved Document: 7, Calculated cosine similarity: 0.08842293537353865\n",
      "\n",
      "south viet nam coping with capricorn in business, count the\n",
      "\n",
      "costs before you act . the moon now in capricorn suggests keeping\n",
      "\n",
      "practical values in mind . tomorrow is rather too energetic for\n",
      "\n",
      "comfort, but that may be because everybody is on the move\n",
      "\n",
      "Retrieved Document: 8, Calculated cosine similarity: 0.06098341370300424\n",
      "\n",
      "south viet nam suicide in many forms a south vietnamese novelist\n",
      "\n",
      "and politician named nguyen tuong tam sent his sons out to buy a bottle\n",
      "\n",
      "of whisky one night last week . for a while he sat drinking with them\n",
      "\n",
      "at his home in saigon . \" my sons, i feel\n",
      "\n",
      "Retrieved Document: 9, Calculated cosine similarity: 0.055924732098079154\n",
      "\n",
      "abruptly, at 9 : 45 p.m., the barrage began first against the\n",
      "\n",
      "palace guard barracks, where a mortar and artillery attack went on for\n",
      "\n",
      "hours . when it came time for the big push on the palace itself, there\n",
      "\n",
      "was a danger that vietnamese and american fa\n",
      "\n",
      "Retrieved Document: 10, Calculated cosine similarity: 0.05343148419043035\n",
      "\n",
      "south viet nam widow's retreat mme . ngo dinh nhu had\n",
      "\n",
      "arrived in the u.s . 5f weeks ago as a crusading wife ; last week she\n",
      "\n",
      "left, an embittered widow . from beverly hills she flew to rome to join\n",
      "\n",
      "her three younger children, son trac, 15, son quyhn,\n",
      "\n",
      "Retrieved Document: 11, Calculated cosine similarity: 0.05223173394436899\n",
      "\n",
      "south viet nam the great emancipator for more than a year, the\n",
      "\n",
      "u.s . has been urging south viet nam's president ngo dinh diem to\n",
      "\n",
      "declare a general amnesty for communist viet cong guerrillas in order\n",
      "\n",
      "to encourage wholesale desertions from the red ca\n",
      "\n",
      "Retrieved Document: 12, Calculated cosine similarity: 0.045199307872082733\n",
      "\n",
      "south viet nam report on the war overshadowed\n",
      "\n",
      "by the political and diplomatic turmoil in saigon, the all but\n",
      "\n",
      "forgotten war against the viet cong continues on its ugly, bloody and\n",
      "\n",
      "wearisome course . the drive against the communists has not diminishe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for doc_no, score in search_res:\n",
    "    counter += 1\n",
    "    print(f\"Retrieved Document: {counter}, Calculated cosine similarity: {score}\\n\")\n",
    "    print(docs[doc_no][:251].strip().lower())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0c8dd-f9a7-42ce-97a6-3819fad2b222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
