{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef3559b",
   "metadata": {},
   "source": [
    "# PS2 Plagiarism Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9450b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"information requirement: query considers the user feedback as information requirement to search\",\n",
    "        \"information retrieval: query depends on the model of information retrieval\",\n",
    "        \"prediction problem: Many problems in information retrieval can be viewed as prediction problems\",\n",
    "        \"search: A search engine is one of applications of information retrieval models\"]\n",
    "\n",
    "new_docs = [\"Feedback: feedback is typically used by the system to modify the query and improve prediction\",\n",
    "            \"information retrieval: ranking in information retrieval algorithms depends on user query\",\n",
    "            \"information problem: query consider on the modey of information retriebal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d763293",
   "metadata": {},
   "source": [
    "1, A) sub_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5c6a4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_binary_distance(vector1, vector2):\n",
    "    dist = 0\n",
    "    \n",
    "    for x1, x2 in zip(vector1, vector2):\n",
    "        dist += abs(x1-x2)\n",
    "    \n",
    "    return dist\n",
    "        \n",
    "\n",
    "def check_duplicate(vector, ref_matrix):\n",
    "    for ref_vec in ref_matrix:\n",
    "        if calculate_binary_distance(vector, ref_vec)==0:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5d870e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_titles = []\n",
    "\n",
    "for doc in docs:\n",
    "    existing_titles.append(doc.split(\":\")[0])\n",
    "\n",
    "new_titles = []\n",
    "\n",
    "for doc in new_docs:\n",
    "    new_titles.append(doc.split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6a285df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['information requirement',\n",
       " 'information retrieval',\n",
       " 'prediction problem',\n",
       " 'search']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "52c337c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feedback', 'information retrieval', 'information problem']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dd68aac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0, 0, 0, 0],\n",
       " [1, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 1, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_map = {}\n",
    "\n",
    "for title in existing_titles:\n",
    "    for word in title.split():\n",
    "        if word in doc_map:\n",
    "            doc_map[word] += 1\n",
    "        else:\n",
    "            doc_map[word] = 1\n",
    "\n",
    "doc_matrix = []\n",
    "\n",
    "for title in existing_titles:\n",
    "    vector = [0]*len(doc_map)\n",
    "    \n",
    "    for word in title.split():\n",
    "        if word in doc_map:\n",
    "            index = list(doc_map.keys()).index(word)\n",
    "            vector[index] = 1\n",
    "    \n",
    "    doc_matrix.append(vector)\n",
    "    \n",
    "doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cbae5998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 0], [1, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_matrix = []\n",
    "\n",
    "for title in new_titles:\n",
    "    vector = [0]*len(doc_map)\n",
    "    \n",
    "    for word in title.split():\n",
    "        if word in doc_map:\n",
    "            index = list(doc_map.keys()).index(word)\n",
    "            vector[index] = 1\n",
    "    \n",
    "    new_matrix.append(vector)\n",
    "    \n",
    "new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecfd2c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information retrieval is an existing title.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_titles)):\n",
    "    if check_duplicate(new_matrix[i], doc_matrix):\n",
    "        print(f\"{new_titles[i]} is an existing title.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba0ff5",
   "metadata": {},
   "source": [
    "1) B subdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3f5d371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4d547922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a7c2d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(td):\n",
    "    td = td.lower()\n",
    "    td = nltk.word_tokenize(td)\n",
    "    \n",
    "    y = []\n",
    "    \n",
    "    for word in td:\n",
    "        if word not in nltk.corpus.stopwords.words('english'):\n",
    "            y.append(word)\n",
    "    \n",
    "    text = y[:]\n",
    "    y = []\n",
    "    \n",
    "    for word in td:\n",
    "        y.append(ps.stem(word))\n",
    "        \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b39db99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query considers the user feedback as information requirement to search',\n",
       " 'query depends on the model of information retrieval',\n",
       " 'Many problems in information retrieval can be viewed as prediction problems',\n",
       " 'A search engine is one of applications of information retrieval models']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_documents = []\n",
    "\n",
    "for doc in docs:\n",
    "    term_documents.append(doc.split(\": \")[1])\n",
    "\n",
    "term_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ce205c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queri consid the user feedback as inform requir to search',\n",
       " 'queri depend on the model of inform retriev',\n",
       " 'mani problem in inform retriev can be view as predict problem',\n",
       " 'a search engin is one of applic of inform retriev model']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in term_documents:\n",
    "    processed_docs.append(transform_text(doc))\n",
    "    \n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "983aa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wik = (TFik/LENi)*log(N+1)/0.5+DFk\n",
    "# TFik - term frequency within doc.\n",
    "# LENi - len of current doc.\n",
    "# N - total docs\n",
    "# DFk - document frequency of the word (no. of documents for which the word exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4bfa26e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "39125597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, mymap):\n",
    "    return mymap[word]\n",
    "\n",
    "def DF(word, corpus_maps):\n",
    "    count = 0\n",
    "    \n",
    "    for hm in corpus_maps:\n",
    "        if word in hm:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def calculate_weights(doc, doc_map, corpus_maps):\n",
    "    vector = [0]*len(doc_map)\n",
    "    \n",
    "    mymap = {}\n",
    "    \n",
    "    for i in doc.split():\n",
    "        if i in mymap:\n",
    "            mymap[i] +=1\n",
    "        else:\n",
    "            mymap[i] = 1\n",
    "    \n",
    "    for word in doc.split():\n",
    "        TFik = TF(word, mymap)\n",
    "        LENi = len(doc)\n",
    "        N = len(corpus_maps)\n",
    "        DFk = DF(word, corpus_maps)\n",
    "        \n",
    "        try:\n",
    "            index = list(doc_map.keys()).index(word)\n",
    "            vector[index] = (TFik/LENi)*(math.log(N+1)/(0.5+DFk))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b4a77b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = {}\n",
    "\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word in doc_map:\n",
    "            doc_map[word] += 1\n",
    "        else:\n",
    "            doc_map[word] = 1\n",
    "\n",
    "doc_matrix = []\n",
    "\n",
    "list_of_maps = []\n",
    "\n",
    "for doc in processed_docs:\n",
    "    hm = {}\n",
    "    \n",
    "    for word in doc.split():\n",
    "        if word in hm:\n",
    "            hm[word] += 1\n",
    "        else:\n",
    "            hm[word] = 1\n",
    "    \n",
    "    list_of_maps.append(hm)\n",
    "\n",
    "for doc in processed_docs:\n",
    "    vector = calculate_weights(doc, doc_map, list_of_maps)\n",
    "    doc_matrix.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f9b23677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.011294301139888422, 0.018823835233147374, 0.011294301139888422, 0.018823835233147374, 0.018823835233147374, 0.011294301139888422, 0.006274611744382457, 0.018823835233147374, 0.018823835233147374, 0.011294301139888422, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.014971515464503257, 0, 0.014971515464503257, 0, 0, 0, 0.0083175085913907, 0, 0, 0, 0.024952525774172098, 0.024952525774172098, 0.014971515464503257, 0.014971515464503257, 0.010693939617502327, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0.010553691229076068, 0.005863161793931149, 0, 0, 0, 0, 0, 0, 0, 0.007538350877911477, 0.01758948538179345, 0.0351789707635869, 0.01758948538179345, 0.01758948538179345, 0.01758948538179345, 0.01758948538179345, 0.01758948538179345, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0.006502779444178183, 0, 0, 0.011705002999520727, 0, 0, 0.011705002999520727, 0.023410005999041455, 0.008360716428229092, 0, 0, 0, 0, 0, 0, 0, 0.01950833833253455, 0.01950833833253455, 0.01950833833253455, 0.01950833833253455, 0.01950833833253455]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb4f77",
   "metadata": {},
   "source": [
    "1) C) Subdiv C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "014565d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feedback is typically used by the system to modify the query and improve prediction',\n",
       " 'ranking in information retrieval algorithms depends on user query',\n",
       " 'query consider on the modey of information retriebal']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_term_docs = []\n",
    "\n",
    "for doc in new_docs:\n",
    "    new_term_docs.append(doc.split(\": \")[1])\n",
    "    \n",
    "new_term_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "90d6f9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feedback is typic use by the system to modifi the queri and improv predict',\n",
       " 'rank in inform retriev algorithm depend on user queri',\n",
       " 'queri consid on the modey of inform retrieb']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_new_docs = []\n",
    "\n",
    "for doc in new_term_docs:\n",
    "    processed_new_docs.append(transform_text(doc))\n",
    "    \n",
    "processed_new_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "615b481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matrix = []\n",
    "\n",
    "for doc in processed_new_docs:\n",
    "    vector = calculate_weights(doc, doc_map, list_of_maps)\n",
    "    new_matrix.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bfc6acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.008699664391535676, 0, 0.017399328783071353, 0, 0.014499440652559464, 0, 0, 0, 0.014499440652559464, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.014499440652559464, 0, 0, 0.014499440652559464, 0, 0], [0.012146701225917737, 0, 0, 0.02024450204319623, 0, 0, 0.006748167347732077, 0, 0, 0, 0.02024450204319623, 0.02024450204319623, 0, 0, 0.008676215161369813, 0, 0, 0.02024450204319623, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.014971515464503257, 0.024952525774172098, 0.014971515464503257, 0, 0, 0, 0.0083175085913907, 0, 0, 0, 0, 0.024952525774172098, 0, 0.014971515464503257, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "106baacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_similarity(vec1, vec2):\n",
    "#     mag1 = 0\n",
    "#     mag2 = 0\n",
    "#     v1_dot_v2 = 0\n",
    "    \n",
    "#     for i in vec1:\n",
    "#         mag1 += i\n",
    "#     for i in vec2:\n",
    "#         mag2 += i\n",
    "    \n",
    "#     mag1 = mag1**0.5\n",
    "#     mag2 = mag2**0.5\n",
    "    \n",
    "#     for i,j in zip(vec1, vec2):\n",
    "#         v1_dot_v2 += i*j\n",
    "        \n",
    "#     return v1_dot_v2/(mag1*mag2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4ac46c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49966535]] 1 1\n",
      "[[0.23204755]] 1 2\n",
      "[[0.12720778]] 1 3\n",
      "[[0.15207872]] 1 4\n",
      "[[0.26640244]] 2 1\n",
      "[[0.63671739]] 2 2\n",
      "[[0.18385498]] 2 3\n",
      "[[0.05004232]] 2 4\n",
      "[[0.400485]] 3 1\n",
      "[[0.63468854]] 3 2\n",
      "[[0.01905523]] 3 3\n",
      "[[0.17040039]] 3 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "for i in range(len(new_matrix)):\n",
    "    for j in range(len(doc_matrix)):\n",
    "        vec1 = np.array(doc_matrix[j])\n",
    "        vec2 = np.array(new_matrix[i])\n",
    "#         print(cosine_similarity([vec1], [vec2]), i+1, j+1)\n",
    "        if cosine_similarity([vec1], [vec2])>=0.85:\n",
    "            print(f\"{i+1}th doc in the system and {j+1}th new doc are similar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ac8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
