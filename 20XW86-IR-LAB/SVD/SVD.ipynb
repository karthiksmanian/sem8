{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e6b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcbffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5760c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = ['reuters dataset reuters benchmark dataset',\n",
    " 'reuters dataset class reuters class',\n",
    " 'document multiple dataset document',\n",
    " 'reuters document document class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087eb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, tf_map):\n",
    "    return tf_map[word]\n",
    "\n",
    "def DF(word, corpus_docmaps):\n",
    "    count = 0\n",
    "    \n",
    "    for hm in corpus_docmaps:\n",
    "        if word in hm:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def calculate_weights(doc, wordcount_map, corpus_docmaps):\n",
    "    vector = [0]*len(wordcount_map)\n",
    "    \n",
    "    tf_map = {}\n",
    "    \n",
    "    for i in doc.split():\n",
    "        if i in tf_map:\n",
    "            tf_map[i] +=1\n",
    "        else:\n",
    "            tf_map[i] = 1\n",
    "    \n",
    "    for word in doc.split():\n",
    "        TFik = TF(word, tf_map)\n",
    "        LENi = sum([tf_map[key] for key in tf_map])\n",
    "        N = len(corpus_docmaps)\n",
    "        DFk = DF(word, corpus_docmaps)\n",
    "        \n",
    "        try:\n",
    "            index = list(wordcount_map.keys()).index(word)\n",
    "            vector[index] = (TFik/LENi)*np.log10((N+1)/(0.5+DFk))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25c877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.061960783994297275, 0.061960783994297275, 0.10457574905606754, 0, 0, 0], [0.061960783994297275, 0.030980391997148637, 0, 0.12041199826559248, 0, 0], [0, 0.0387254899964358, 0, 0, 0.1505149978319906, 0.1307196863200844], [0.0387254899964358, 0, 0, 0.0752574989159953, 0.1505149978319906, 0]]\n"
     ]
    }
   ],
   "source": [
    "word_countmap = {}\n",
    "\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word in word_countmap:\n",
    "            word_countmap[word] += 1\n",
    "        else:\n",
    "            word_countmap[word] = 1\n",
    "\n",
    "corpus_docmaps = []\n",
    "\n",
    "for doc in processed_docs:\n",
    "    hm = {}\n",
    "    \n",
    "    for word in doc.split():\n",
    "        if word in hm:\n",
    "            hm[word] += 1\n",
    "        else:\n",
    "            hm[word] = 1\n",
    "    \n",
    "    corpus_docmaps.append(hm)\n",
    "\n",
    "\n",
    "doc_matrix = []\n",
    "for doc in processed_docs:\n",
    "    vector = calculate_weights(doc, word_countmap, corpus_docmaps)\n",
    "    doc_matrix.append(vector)\n",
    "    \n",
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e78b17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.061960783994297275, 0.061960783994297275, 0.10457574905606754, 0, 0, 0],\n",
       " [0.061960783994297275, 0.030980391997148637, 0, 0.12041199826559248, 0, 0],\n",
       " [0, 0.0387254899964358, 0, 0, 0.1505149978319906, 0.1307196863200844],\n",
       " [0.0387254899964358, 0, 0, 0.0752574989159953, 0.1505149978319906, 0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbdd4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272c2e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06196078, 0.06196078, 0.10457575, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.06196078, 0.03098039, 0.        , 0.120412  , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.03872549, 0.        , 0.        , 0.150515  ,\n",
       "        0.13071969],\n",
       "       [0.03872549, 0.        , 0.        , 0.0752575 , 0.150515  ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99816046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27de8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, singular, V_transpose = svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2c8e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.10590786,  0.48741856, -0.83707353,  0.22475449],\n",
       "        [ 0.20817907,  0.71593621,  0.28097206, -0.60427769],\n",
       "        [ 0.74414148, -0.45097763, -0.27775407, -0.40709374],\n",
       "        [ 0.62585818,  0.21558681,  0.37843796,  0.64699968]]),\n",
       " (4, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10064a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24692696, 0.16097876, 0.12803432, 0.07544964])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1886769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.17696625,  0.16939765,  0.04485291,  0.29226367,  0.83508701,\n",
       "          0.39393811],\n",
       "        [ 0.51503384,  0.21690123,  0.31663904,  0.63630651, -0.22009021,\n",
       "         -0.36620765],\n",
       "        [-0.15465609, -0.42111575, -0.6837041 ,  0.48668747,  0.11836228,\n",
       "         -0.28357962],\n",
       "        [ 0.02040864, -0.27249565,  0.3115173 , -0.31903008,  0.47858996,\n",
       "         -0.70530705],\n",
       "        [ 0.81629389, -0.13462596, -0.40388599, -0.38540548, -0.01731873,\n",
       "          0.05982408],\n",
       "        [ 0.11292632, -0.80903757,  0.4124436 ,  0.15004566, -0.10407726,\n",
       "          0.35951406]]),\n",
       " (6, 6))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_transpose, V_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0963334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
