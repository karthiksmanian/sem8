{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d8eb0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "756a4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "query = \"\"\n",
    "stopwords = set(['is', 'was', 'the', 'are', 'a', 'an'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "719214c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\D drive\\PSG\\sem8\\20XW86-IR-LAB\\vsm-practice-ca\\documents\\d1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c3ef968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    f = open(f\"C:/D drive/PSG/sem8/20XW86-IR-LAB/vsm-practice-ca/documents/d{i}.txt\", 'r')\n",
    "    docs.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "35215e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"C:/D drive/PSG/sem8/20XW86-IR-LAB/vsm-practice-ca/documents/query.txt\", 'r')\n",
    "query = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "696a263f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reuters, dataset, Reuters, benchmark, dataset',\n",
       " 'Reuters, dataset, class, Reuters, class',\n",
       " 'document, _multiple, dataset, document',\n",
       " 'Reuters document, document, class']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "841c572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reuters, document, dataset'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "862c04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c575a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.split()\n",
    "    y = []\n",
    "    \n",
    "    for word in text:\n",
    "        char_list = []\n",
    "        for c in word:\n",
    "            if c not in string.punctuation:\n",
    "                char_list.append(c)\n",
    "        \n",
    "        lcase_word = ''.join(char_list[:]).lower()\n",
    "        \n",
    "        if lcase_word.isalnum() and lcase_word not in stopwords:\n",
    "            y.append(lcase_word)\n",
    "\n",
    "    return ' '.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "e6a703a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reuters dataset reuters benchmark dataset'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a1e5e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    processed_docs.append(transform_text(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "63aa0ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reuters dataset reuters benchmark dataset',\n",
       " 'reuters dataset class reuters class',\n",
       " 'document multiple dataset document',\n",
       " 'reuters document document class']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ab7eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF score calc.\n",
    "# Wij = (TFk/LENk)*log(N+1/DFk+0.5)\n",
    "# TFi - term freq within doc.\n",
    "# LENi - len of document.\n",
    "# N - total docs\n",
    "# DFk - document frequency of the word K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "289d7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, tf_map):\n",
    "    return tf_map[word]\n",
    "\n",
    "def DF(word, corpus_docmaps):\n",
    "    count = 0\n",
    "    \n",
    "    for hm in corpus_docmaps:\n",
    "        if word in hm:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def calculate_weights(doc, wordcount_map, corpus_docmaps):\n",
    "    vector = [0]*len(wordcount_map)\n",
    "    \n",
    "    tf_map = {}\n",
    "    \n",
    "    for i in doc.split():\n",
    "        if i in tf_map:\n",
    "            tf_map[i] +=1\n",
    "        else:\n",
    "            tf_map[i] = 1\n",
    "    \n",
    "    for word in doc.split():\n",
    "        TFik = TF(word, tf_map)\n",
    "        LENi = sum([tf_map[key] for key in tf_map])\n",
    "        N = len(corpus_docmaps)\n",
    "        DFk = DF(word, corpus_docmaps)\n",
    "        \n",
    "        try:\n",
    "            index = list(wordcount_map.keys()).index(word)\n",
    "            vector[index] = (TFik/LENi)*np.log10((N+1)/(0.5+DFk))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b40f067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.061960783994297275, 0.061960783994297275, 0.10457574905606754, 0, 0, 0], [0.061960783994297275, 0.030980391997148637, 0, 0.12041199826559248, 0, 0], [0, 0.0387254899964358, 0, 0, 0.1505149978319906, 0.1307196863200844], [0.0387254899964358, 0, 0, 0.0752574989159953, 0.1505149978319906, 0]]\n"
     ]
    }
   ],
   "source": [
    "word_countmap = {}\n",
    "\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word in word_countmap:\n",
    "            word_countmap[word] += 1\n",
    "        else:\n",
    "            word_countmap[word] = 1\n",
    "\n",
    "corpus_docmaps = []\n",
    "\n",
    "for doc in processed_docs:\n",
    "    hm = {}\n",
    "    \n",
    "    for word in doc.split():\n",
    "        if word in hm:\n",
    "            hm[word] += 1\n",
    "        else:\n",
    "            hm[word] = 1\n",
    "    \n",
    "    corpus_docmaps.append(hm)\n",
    "\n",
    "\n",
    "doc_matrix = []\n",
    "for doc in processed_docs:\n",
    "    vector = calculate_weights(doc, word_countmap, corpus_docmaps)\n",
    "    doc_matrix.append(vector)\n",
    "    \n",
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f869356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = calculate_weights(transform_text(query), word_countmap, corpus_docmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2c759915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05163398666191439, 0.05163398666191439, 0, 0, 0.10034333188799373, 0]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0337d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_prod = sum([x*y for x,y in zip(vec1, vec2)])\n",
    "    mag1 = sum([x*x for x in vec1])**0.5\n",
    "    mag2 = sum([y*y for y in vec2])**0.5\n",
    "\n",
    "    return dot_prod/mag1*mag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6e6d9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a091fb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006398564588646609 0.13643447070668593 0.12410044887747008\n",
      "0.004798923441484956 0.13891714353454726 0.12410044887747008\n",
      "0.017102727815528154 0.20308142342284646 0.12410044887747008\n",
      "0.017102727815528154 0.17267923815826622 0.12410044887747008\n"
     ]
    }
   ],
   "source": [
    "for i,dv in enumerate(doc_matrix):\n",
    "    res.append([i+1,cosine_similarity(dv, query_vector)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "354f9dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 0.01229132246339271],\n",
       " [3, 0.010451257250235832],\n",
       " [1, 0.005820118138103466],\n",
       " [2, 0.004287077448211349]]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(res, key= lambda x:x[1], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
