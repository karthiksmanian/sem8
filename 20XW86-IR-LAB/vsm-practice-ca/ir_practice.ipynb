{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8eb0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "756a4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "query = \"\"\n",
    "stopwords = set(['is', 'was', 'the', 'are', 'a', 'an'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3ef968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    f = open(f\"C:\\D drive/PSG/sem8/20XW86-IR-LAB/catest1/documents/d{i}.txt\", 'r')\n",
    "    docs.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35215e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"C:\\D drive/PSG/sem8/20XW86-IR-LAB/catest1/documents/query.txt\", 'r')\n",
    "query = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "696a263f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reuters, dataset, Reuters, benchmark, dataset',\n",
       " 'Reuters, dataset, class, Reuters, class',\n",
       " 'document, _multiple, dataset, document',\n",
       " 'Reuters document, document, class']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "841c572f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reuters, document, dataset'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "862c04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c575a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.split()\n",
    "    y = []\n",
    "    \n",
    "    for word in text:\n",
    "        char_list = []\n",
    "        for c in word:\n",
    "            if c not in string.punctuation:\n",
    "                char_list.append(c)\n",
    "        \n",
    "        lcase_word = ''.join(char_list[:]).lower()\n",
    "        \n",
    "        if lcase_word.isalnum() and lcase_word not in stopwords:\n",
    "            y.append(lcase_word)\n",
    "\n",
    "    return ' '.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6a703a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reuters dataset reuters benchmark dataset'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1e5e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    processed_docs.append(transform_text(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63aa0ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reuters dataset reuters benchmark dataset',\n",
       " 'reuters dataset class reuters class',\n",
       " 'document multiple dataset document',\n",
       " 'reuters document document class']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab7eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF score calc.\n",
    "# Wij = (TFk/LENk)*log(N+1/DFk+0.5)\n",
    "# TFi - term freq within doc.\n",
    "# LENi - len of document.\n",
    "# N - total docs\n",
    "# DFk - document frequency of the word K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "289d7a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TF(word, wordcount_map):\n",
    "    return wordcount_map[word]\n",
    "\n",
    "def DF(word, corpus_docmaps):\n",
    "    count = 0\n",
    "    \n",
    "    for hm in corpus_docmaps:\n",
    "        if word in hm:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def calculate_weights(doc, wordcount_map, corpus_docmaps):\n",
    "    vector = [0]*len(wordcount_map)\n",
    "    \n",
    "    mymap = {}\n",
    "    \n",
    "    for i in doc.split():\n",
    "        if i in mymap:\n",
    "            mymap[i] +=1\n",
    "        else:\n",
    "            mymap[i] = 1\n",
    "    \n",
    "    for word in doc.split():\n",
    "        TFik = TF(word, wordcount_map)\n",
    "        LENi = len(doc)\n",
    "        N = len(corpus_docmaps)\n",
    "        DFk = DF(word, corpus_docmaps)\n",
    "        \n",
    "        try:\n",
    "            index = list(wordcount_map.keys()).index(word)\n",
    "            vector[index] = (TFik/LENi)*(math.log(N+1)/(0.5+DFk))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b40f067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05607797604300001, 0.04486238083440001, 0.026169722153400007, 0, 0, 0], [0.06569134336465715, 0.05255307469172572, 0, 0.055180728426312005, 0, 0], [0, 0.05409875335912942, 0, 0, 0.07573825470278119, 0.03155760612615883], [0.07416764573429033, 0, 0, 0.062300822416803875, 0.08306776322240517, 0]]\n"
     ]
    }
   ],
   "source": [
    "word_countmap = {}\n",
    "\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word in word_countmap:\n",
    "            word_countmap[word] += 1\n",
    "        else:\n",
    "            word_countmap[word] = 1\n",
    "\n",
    "corpus_docmaps = []\n",
    "\n",
    "for doc in processed_docs:\n",
    "    hm = {}\n",
    "    \n",
    "    for word in doc.split():\n",
    "        if word in hm:\n",
    "            hm[word] += 1\n",
    "        else:\n",
    "            hm[word] = 1\n",
    "    \n",
    "    corpus_docmaps.append(hm)\n",
    "\n",
    "\n",
    "doc_matrix = []\n",
    "for doc in processed_docs:\n",
    "    vector = calculate_weights(doc, word_countmap, corpus_docmaps)\n",
    "    doc_matrix.append(vector)\n",
    "    \n",
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f869356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = calculate_weights(transform_text(query), word_countmap, corpus_docmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c759915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09579987574012501, 0.0766399005921, 0, 0, 0.10729586082894, 0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0337d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_prod = sum([x*y for x,y in zip(vec1, vec2)])\n",
    "    mag1 = sum([x*x for x in vec1])**0.5\n",
    "    mag2 = sum([y*y for y in vec2])**0.5\n",
    "    \n",
    "    return dot_prod/mag1*mag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e6d9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a091fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,dv in enumerate(doc_matrix):\n",
    "    res.append([i+1,cosine_similarity(dv, query_vector)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "354f9dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 0.020459465635116483],\n",
       " [3, 0.02035239940183222],\n",
       " [1, 0.018786943639801365],\n",
       " [2, 0.016719605955572377]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(res, key= lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2276e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
